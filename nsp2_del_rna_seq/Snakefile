import pandas as pd
from collections import defaultdict
# Download
dir = '/rna/han/gigyf2_nsp2/exp_data/del_rnaseq'
summfile = '__resources/sample_list.csv'
summtbl = pd.read_csv(summfile, index_col=0)
samples = []
namematch = {}
for barcode, row in summtbl.iterrows():
    name = row['name']
    namematch[name]=str(barcode)
    samples.append(name)
fraglen = 300
thread = 32
################################################################################
TARGETS = [ #expand('rawdata/{sample}.r1.fq.gz', sample=samples),
            #expand('rawdata/{sample}.fastqc.html',sample=samples),
            'results/summary_graph.png',
            'results/featurecount.csv',
            'png/featurecount_scatter.png',
           ]

################################################################################

rule all:
    input: TARGETS

################################################################################
rule rename:
    input: r1 = lambda wildcards: "rawdata/"+namematch[wildcards.sample]+"_1.fq.gz", \
           r2 = lambda wildcards: "rawdata/"+namematch[wildcards.sample]+"_2.fq.gz"
    output: r1 = 'rawdata/{sample}.r1.fastq.gz', \
            r2 = 'rawdata/{sample}.r2.fastq.gz'
    threads: 8
    priority: 50
    run:
        shell('mv {input.r1} {output.r1}')
        shell('mv {input.r2} {output.r2}')

rule qc_stats:
    input: 'rawdata/{sample}.r1.fastq.gz'
    output: 'rawdata/{sample}.r1.fastqc.html'
    threads: 8
    shell: 'fastqc -t {threads} -o rawdata {input}'

rule STAR_index:
    input: fa = '{ref_dir}/genomic.fna',
           gff = '{ref_dir}/genomic.gtf'
    output: '{ref_dir}/star_{sjdb}/Genome'
    threads: 128
    run:
        idx_dir = str(output).replace("/Genome","")
        shell('STAR --runThreadN {threads} --runMode genomeGenerate --genomeDir {idx_dir} \
               --genomeFastaFiles {input.fa} --sjdbGTFfile {input.gff} --sjdbOverhang {wildcards.sjdb}')

rule align:
    input: r1 = dir + '/rawdata/{sample}.r1.fastq.gz', r2 = dir + '/rawdata/{sample}.r2.fastq.gz',
           idx = '/rna/han/gigyf2_nsp2/exp_data/fclip_seq/HD/grch38_sars_cov_2/star_{sjdb}/Genome'.format(sjdb=fraglen-1)
    output: 'alignments/{sample}.total.bam'
    threads: thread
    run:
        out_pfx = 'alignments/' + wildcards.sample + '.'
        tmpdir = 'alignments/' + wildcards.sample + '.tmp'
        index = str(input.idx).replace('/Genome', "")
        shell('STAR --runThreadN {threads} --readFilesIn {input.r1} {input.r2} --readFilesCommand zcat \
               --alignEndsType Local --genomeDir {index} --genomeLoad LoadAndRemove \
               --outStd BAM_SortedByCoordinate --outSAMtype BAM SortedByCoordinate --outSAMunmapped None \
               --outFilterType BySJout --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 \
               --alignSJstitchMismatchNmax -1 -1 -1 -1 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \
               --outFilterMismatchNoverReadLmax 0.04 --outFilterMismatchNmax 999 --outFilterMultimapNmax 20 \
               --scoreGapNoncan -4 --scoreGapATAC -4 \
               --outSJfilterOverhangMin 12 12 12 12 --outSJfilterCountUniqueMin 1 1 1 1 \
               --outSJfilterCountTotalMin 1 1 1 1 --outSJfilterDistToOtherSJmin 0 0 0 0 \
               --chimOutType WithinBAM HardClip --chimScoreJunctionNonGTAG 0 --chimSegmentMin 20 \
               --limitBAMsortRAM 100000000000 --outTmpDir {tmpdir} --outFileNamePrefix {out_pfx} > {output[0]}')

rule uniq:
    input: 'alignments/{sample}.total.bam'
    output: bam='alignments/{sample}.uniq.bam', bai='alignments/{sample}.uniq.bam.bai'
    threads: 8
    run:
        shell('samtools view -b -@ {threads} -q 4 {input} -o {output.bam}')
        shell('samtools index {output.bam}')

## Get preprocessing and alignment summary
rule get_summary:
    input: dir + '/rawdata/{sample}.r1.fastq.gz',
           'alignments/{sample}.total.bam', 'alignments/{sample}.uniq.bam'
    output: 'alignments/{sample}.summary'
    threads: 8
    run:
        shell('unpigz -p {threads} {input[0]} -c | awk "END {{print NR / 4}}" >> {output}')
        for i in range(1, 3):
            inputfile = str(input[i])
            shell('samtools view -@ {threads} -F 256 -c {inputfile} | awk \'{{print $1 / 2}}\' >> {output}')

rule summary_graph:
    input: ['alignments/' + x + '.summary' for x in samples]
    output: 'results/summary_graph.png'
    shell: 'mkdir results -p &&'
           'python __resources/rna_summary_graph_cov2.py {output}'

rule sort_bam:
    input: 'alignments/{sample}.uniq.bam'
    output: temp('featurecount/{sample}.uniq.bam')
    threads: 8
    shell: 'samtools sort -@ {threads} -n -o {output} {input}'

rule featurecount:
    input: 'featurecount/' + x + '.uniq.bam' for x in samples
    output: 'featurecount/{sample}.txt'
    params: bam = 'featurecount/{sample}.uniq.bam',
            annot = '/rna/han/gigyf2_nsp2/exp_data/fclip_seq/HD/grch38_sars_cov_2/genomic.gtf'
    threads: 16
    shell: 'featureCounts -a {params.annot} -p -s 2 -T {threads} --countReadPairs -o {output} {params.bam}'

rule featurecount_count:
    input: 'featurecount/' + x + '.txt' for x in samples
    output: 'results/featurecount.csv'
    params: 'host'
    shell: 'mkdir results -p &&'
           'python __resources/featurecount.py {params}'

rule scatter:
    input: 'results/{quant}.csv'
    output: 'png/{quant}_scatter.png'
    shell: 'mkdir -p png && mkdir -p pdf &&'
           'python __resources/rpm_scatter.py {input} {output}'

# vim: et syntax=snakemake